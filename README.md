## Style Transfer GAN

This folder contains three subfolders:
The "style-transfer-gan" subfolder contains code for the large model part. This section uses a small number of samples to perform transfer learning on StyleGAN2, which is then merged with a face model pre-trained on FFHQ to achieve style learning effects. By controlling the degree of transfer learning and the model fusion scheme, we can effectively control the degree of style learning to achieve our desired effects.

The "mobile-p2p" subfolder contains code for the small model part intended for mobile deployment. This section uses a large number of sample pairs generated by the large model to perform supervised training on the small model. While ensuring learning effectiveness, the small model's parameter count and inference time are adjusted through model pruning and distillation schemes to achieve real-time effect generation that can be deployed on mobile devices.

The "utils" subfolder contains scripts used for image post-processing. The process described above is greatly simplified. In reality, the samples generated by the large model cannot be directly used for small model training. A large amount of image processing and fine-tuning is required to reduce the learning burden on the small model, thereby improving the small model's learning effectiveness.
For specific usage of each part of the code, please refer to the README.md file in each folder.