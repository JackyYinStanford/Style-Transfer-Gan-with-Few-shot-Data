{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import config\n",
    "from encoder.generator_model import Generator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrained_networks\n",
    "blended_url = './checkpoints/us_comics/000036/blended-128.pkl'\n",
    "ffhq_url = './weights/stylegan2-ffhq-config-f.pkl'\n",
    "_, _, Gs_blended = pretrained_networks.load_networks(blended_url)\n",
    "_, _, Gs = pretrained_networks.load_networks(ffhq_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def generate_image(latent_vector):\n",
    "\n",
    "    latent = np.expand_dims(latent_vector, axis=0)\n",
    "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False),\n",
    "                                    minibatch_size=8)\n",
    "    tar_images = Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\n",
    "    ori_images = Gs.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs)\n",
    "    tar_images = Image.fromarray(tar_images.transpose((0, 2, 3, 1))[0], 'RGB')\n",
    "    ori_images = Image.fromarray(ori_images.transpose((0, 2, 3, 1))[0], 'RGB')\n",
    "    return ori_images, tar_images\n",
    "\n",
    "def move_and_show(latent_vector, direction, coeffs, save_name):\n",
    "    fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
    "    for i, coeff in enumerate(coeffs):\n",
    "        new_latent_vector = latent_vector.copy()\n",
    "        new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
    "        ori_images, tar_images = generate_image(new_latent_vector)\n",
    "        ax[i].imshow(tar_images)\n",
    "        ax[i].set_title('Ori coeff: %0.1f' % coeff)\n",
    "        ori_images.save(f\"/localhome/local-jackyyin/Style-Transfer-Gan-with-Few-shot-Data/style-transfer-gan/final_vis/us_comics/{save_name}_ori_{i}.png\")\n",
    "        tar_images.save(f\"/localhome/local-jackyyin/Style-Transfer-Gan-with-Few-shot-Data/style-transfer-gan/final_vis/us_comics/{save_name}_tar_{i}.png\")\n",
    "#         ax[2*i].imshow(tar_images)\n",
    "#         ax[2*i].set_title('Tar Coeff: %0.1f' % coeff)\n",
    "    [x.axis('off') for x in ax]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading already learned representations\n",
    "andrew = np.load('/localhome/local-jackyyin/Style-Transfer-Gan-with-Few-shot-Data/style-transfer-gan/generated/celebrity/20241126-180511_01.npy')\n",
    "donald = np.load('/localhome/local-jackyyin/Style-Transfer-Gan-with-Few-shot-Data/style-transfer-gan/generated/celebrity/20241126-180845_01.npy')\n",
    "harris = np.load('/localhome/local-jackyyin/Style-Transfer-Gan-with-Few-shot-Data/style-transfer-gan/generated/celebrity/20241126-180825_01.npy')\n",
    "jennier = np.load('/localhome/local-jackyyin/Style-Transfer-Gan-with-Few-shot-Data/style-transfer-gan/generated/celebrity/20241126-180943_01.npy')\n",
    "\n",
    "# Of course you can learn your own vectors using two scripts\n",
    "\n",
    "# 1) Extract and align faces from images\n",
    "# python align_images.py raw_images/ aligned_images/\n",
    "\n",
    "# 2) Find latent representation of aligned images\n",
    "# python encode_images.py aligned_images/ generated_images/ latent_representations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading already learned latent directions\n",
    "smile_direction = np.load('ffhq_dataset/latent_directions/smile.npy')\n",
    "gender_direction = np.load('ffhq_dataset/latent_directions/gender.npy')\n",
    "age_direction = np.load('ffhq_dataset/latent_directions/age.npy')\n",
    "\n",
    "# In general it's possible to find directions of almost any face attributes: position, hair style or color ... \n",
    "# Additional scripts for doing so will be realised soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smile transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(donald, smile_direction, [-5, 0, 10], 'donald')\n",
    "move_and_show(andrew, smile_direction, [-5, 0, 10], 'andrew')\n",
    "move_and_show(harris, smile_direction, [-5, 0, 10], 'harris')\n",
    "move_and_show(jennier, smile_direction, [-5, 0, 10], 'jennier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(hillary_clinton, smile_direction, [-1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(donald_trump, gender_direction, [-2, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(hillary_clinton, gender_direction, [-1.5, 0, 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_show(hillary_clinton, age_direction, [-2, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it yourself!\n",
    "move_and_show(donald_trump, age_direction, [-3, 0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
